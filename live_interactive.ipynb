{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be3ff078-65ec-4793-8bec-1b23f6a39964",
   "metadata": {},
   "source": [
    "Proposed steps\n",
    "* Visit direct link at https://www.sportybet.com/ng/sport/football/live_list\n",
    "* Identify HT tag (\"game-id\")\n",
    "* Identify scores tags (two \"score-item\" within the \"score\" div)\n",
    "* Identify matches with 0 total goals at HT (add the two \"score-item\")\n",
    "* Extract [title] of class \"teams\" and extract home and away team names (the tags are \"home-team\" and \"away-team\")\n",
    "* Extracted data should be loaded into a csv file with the column titles: title,home-team,away-team,ht_goals\n",
    "* Read the output csv with pandas and display the content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4b96e9",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4b881d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è SoccerData library not installed. Run: pip install soccerdata\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from urllib.parse import urljoin\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# SoccerData imports (install with: pip install soccerdata)\n",
    "try:\n",
    "    import soccerdata as sd\n",
    "    SOCCERDATA_AVAILABLE = True\n",
    "    print(\"‚úÖ SoccerData library available\")\n",
    "except ImportError:\n",
    "    SOCCERDATA_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è SoccerData library not installed. Run: pip install soccerdata\")\n",
    "\n",
    "# Uncomment the following lines if packages are not installed\n",
    "# print(\"üì¶ Installing required packages...\")\n",
    "# !pip install requests beautifulsoup4 pandas lxml selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f6646f",
   "metadata": {},
   "source": [
    "### Load Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a02d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_headers():\n",
    "    \"\"\"Load and return a random set of headers from the JSON file.\"\"\"\n",
    "    # Get the directory where the current script is located\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    headers_file = os.path.join(script_dir, 'browser_headers.json')\n",
    "    \n",
    "    try:\n",
    "        with open(headers_file, 'r') as f:\n",
    "            headers_list = json.load(f)\n",
    "        \n",
    "        # Return a random set of headers\n",
    "        return random.choice(headers_list)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        # Fallback to your original headers if file not found\n",
    "        return {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "        }\n",
    "\n",
    "\n",
    "def scrape_sb_live():\n",
    "    \"\"\"\n",
    "    Scrapes SportyBet live football matches and extracts halftime data\n",
    "    Returns a list of dictionaries containing match data\n",
    "    \"\"\"\n",
    "    url = \"https://www.sportybet.com/ng/sport/football/live_list\"\n",
    "    \n",
    "    # Headers to mimic a real browser\n",
    "    # headers = get_random_headers()\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"none\",\n",
    "        \"Sec-Fetch-User\": \"?1\"\n",
    "    }\n",
    "    \n",
    "    print(\"üåê Fetching data...\")\n",
    "    \n",
    "    try:\n",
    "        # Set up headless Chrome\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")  # Run without opening a browser window\n",
    "        chrome_options.add_argument(\"--no-sandbox\")  # For stability in some environments\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Avoid resource issues\n",
    "        chrome_options.add_argument(\"--disable-gpu\")  # Additional stability\n",
    "        chrome_options.add_argument(\"--disable-extensions\")\n",
    "        chrome_options.add_argument(\"--disable-logging\")  # Reduce log noise\n",
    "        chrome_options.add_argument(\"--log-level=3\")  # Only fatal errors\n",
    "        chrome_options.add_argument(f\"user-agent={headers['User-Agent']}\")  # Reuse your user-agent for consistency\n",
    "        \n",
    "        # Initialize driver\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        \n",
    "        print(\"üõ†Ô∏è Initializing browser...\")\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for JS to load (adjust timeout if needed; 10 seconds should suffice for this site)\n",
    "        driver.implicitly_wait(10)\n",
    "        \n",
    "        # print(\"‚úÖ Page loaded with JS rendered\")\n",
    "\n",
    "        # Get page source and clean it before parsing\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "        # Clean the page source to remove any problematic content\n",
    "        # Remove any WebDriver-related paths that might be causing issues\n",
    "        page_source = re.sub(r'/[^<>]*?\\.wdm/[^<>]*?chromedriver[^<>]*?', '', page_source)\n",
    "        page_source = re.sub(r'\\[[^<>\\[\\]]*?chromedriver[^<>\\[\\]]*?\\]', '', page_source)\n",
    "\n",
    "        # Parse with explicit parser and error handling\n",
    "        try:\n",
    "            # Try html.parser first (most robust)\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        except Exception as e1:\n",
    "            print(f\"‚ö†Ô∏è html.parser failed: {e1}\")\n",
    "            try:\n",
    "                # Fallback to lxml if available\n",
    "                soup = BeautifulSoup(page_source, 'lxml')\n",
    "            except Exception as e2:\n",
    "                print(f\"‚ö†Ô∏è lxml parser failed: {e2}\")\n",
    "                # Last resort - use html5lib if available\n",
    "                try:\n",
    "                    soup = BeautifulSoup(page_source, 'html5lib')\n",
    "                except Exception as e3:\n",
    "                    print(f\"‚ùå All parsers failed. html5lib error: {e3}\")\n",
    "                    return []\n",
    "        \n",
    "        # # Parse the fully rendered HTML\n",
    "        # soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # driver.quit()  # Clean up browser session\n",
    "        \n",
    "        # Find all matches with the correct class structure\n",
    "        matches = soup.find_all('div', class_='m-table-row m-content-row match-row football-row')\n",
    "        print(f\"üéÆ Found {len(matches)} ongoing events\")\n",
    "        \n",
    "        extracted_data = []\n",
    "        halftime_matches = 0\n",
    "        first_half_matches = 0\n",
    "        second_half_matches = 0\n",
    "        zero_goal_matches = 0\n",
    "\n",
    "        # Load watchlist CSV\n",
    "        try:\n",
    "            watchlist_df = pd.read_csv('watchlist_today.csv')\n",
    "            watchlist_titles = set(watchlist_df['title'])  # Convert titles to a set for O(1) lookup\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not load watchlist_today.csv: {e}\")\n",
    "            watchlist_titles = set()\n",
    "        \n",
    "        for match in matches:\n",
    "            try:                \n",
    "                # Check if this is a halftime match\n",
    "                left_team_cell = match.find(class_='m-table-cell left-team-cell')\n",
    "                is_halftime = False\n",
    "                is_first_half = False\n",
    "                is_second_half = False\n",
    "\n",
    "                if left_team_cell:\n",
    "                    left_team_table = left_team_cell.find(class_='left-team-table')\n",
    "                    if left_team_table:\n",
    "                        game_id_elem = left_team_table.find(class_='game-id')\n",
    "                        if game_id_elem:\n",
    "                            time_text = game_id_elem.get_text(strip=True).upper()\n",
    "                            # print(f\"Game ID text: {time_text}\")  # Debug output\n",
    "                            is_halftime = any(x in time_text for x in ['HT', 'HALF', 'HALFTIME', 'HALF-TIME'])\n",
    "                            is_first_half = any(x in time_text for x in ['H1', '1ST', 'FIRST'])\n",
    "                            is_second_half = any(x in time_text for x in ['H2', '2ND', 'SECOND'])\n",
    "\n",
    "                # Skip if not a halftime, first half, or second half match\n",
    "                if not (is_halftime or is_first_half or is_second_half):\n",
    "                    continue\n",
    "\n",
    "                # Update counters\n",
    "                if is_halftime:\n",
    "                    halftime_matches += 1\n",
    "                if is_first_half:\n",
    "                    first_half_matches = first_half_matches + 1 if 'first_half_matches' in locals() else 1\n",
    "                if is_second_half:\n",
    "                    second_half_matches = second_half_matches + 1 if 'second_half_matches' in locals() else 1\n",
    "                \n",
    "                # Find teams container\n",
    "                teams_container = match.find(class_='teams')\n",
    "                if not teams_container:\n",
    "                    continue\n",
    "                \n",
    "                # Extract team names\n",
    "                home_team_elem = teams_container.find(class_='home-team')\n",
    "                away_team_elem = teams_container.find(class_='away-team')\n",
    "                \n",
    "                if not home_team_elem or not away_team_elem:\n",
    "                    continue\n",
    "                \n",
    "                home_team = home_team_elem.get_text(strip=True)\n",
    "                away_team = away_team_elem.get_text(strip=True)\n",
    "                \n",
    "                # Extract title from teams container\n",
    "                title = teams_container.get('title', f\"{home_team} vs {away_team}\")\n",
    "                \n",
    "                # Find score container\n",
    "                score_container = match.find(class_='score')\n",
    "                if not score_container:\n",
    "                    continue\n",
    "                \n",
    "                # Find score items\n",
    "                score_items = score_container.find_all(class_='score-item')\n",
    "                if len(score_items) < 2:\n",
    "                    continue\n",
    "                \n",
    "                # Extract scores and convert to integers\n",
    "                try:\n",
    "                    home_score = int(score_items[0].get_text(strip=True))\n",
    "                    away_score = int(score_items[1].get_text(strip=True))\n",
    "                    total_goals = home_score + away_score\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "                \n",
    "                # Only include matches with 0 total goals at HT\n",
    "                if total_goals == 0 and is_halftime:\n",
    "                    match_data = {\n",
    "                        'title': title,\n",
    "                        'home-team': home_team,\n",
    "                        'away-team': away_team,\n",
    "                        'ht_goals': total_goals\n",
    "                    }\n",
    "                    extracted_data.append(match_data)\n",
    "                    zero_goal_matches += 1\n",
    "                    print(f\"‚öΩ 0-goal HT event: {home_team} vs {away_team}\")\n",
    "                    # if title in watchlist_titles:\n",
    "                    #     print(f\"üëÄ‚≠ê Watchlist event: {home_team} vs {away_team}\")\n",
    "                    # else:\n",
    "                    #     print(f\"‚öΩ 0-goal HT event: {home_team} vs {away_team}\")\n",
    "                    # Attempt to find SofaScore URL\n",
    "                    # print(search_sofascore_match(home_team, away_team))\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error processing match: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\nüìä Summary:\")\n",
    "        # print(f\"   - Total events found: {len(matches)}\")\n",
    "        print(f\"   - HT: {halftime_matches}, H1: {first_half_matches}, H2: {second_half_matches}\")\n",
    "        print(f\"   - 0 at HT events: {zero_goal_matches}\")\n",
    "        \n",
    "        return extracted_data\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Error fetching data: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def save_to_csv(data, filename=None):\n",
    "    \"\"\"\n",
    "    Save extracted data to CSV file with timestamp\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"‚ùå No data to save\")\n",
    "        return False, None\n",
    "    \n",
    "    if filename is None:\n",
    "        # Generate filename with current timestamp\n",
    "        current_time = datetime.now()\n",
    "        filename = f\"sb_{current_time.strftime('%d-%m-%y-%H-%M-%S')}.csv\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"üíæ Data saved to {filename}\")\n",
    "        return True, filename\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving to CSV: {e}\")\n",
    "        return False, None\n",
    "    \n",
    "\n",
    "def get_history_stats_soccerdata(home_team, away_team, league=None, season=\"2024-25\"):\n",
    "    \"\"\"\n",
    "    Extract match statistics using SoccerData library from multiple sources\n",
    "    Returns dictionary with comprehensive match stats\n",
    "    \"\"\"\n",
    "    if not SOCCERDATA_AVAILABLE:\n",
    "        print(\"‚ùå SoccerData library not available\")\n",
    "        return None\n",
    "    \n",
    "    stats_data = {\n",
    "        # 'attempts_home': 0, 'attempts_away': 0,\n",
    "        # 'on_target_home': 0, 'on_target_away': 0,\n",
    "        # 'corners_home': 0, 'corners_away': 0,\n",
    "        'l5g_home_gf': 0, 'l5g_home_ga': 0,\n",
    "        'l5g_away_gf': 0, 'l5g_away_ga': 0,\n",
    "        'data_source': 'soccerdata'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîç Using SoccerData for: {home_team} vs {away_team}\")\n",
    "        \n",
    "        # Try FotMob first (good for live match stats)\n",
    "        try:\n",
    "            fotmob = sd.FotMob()\n",
    "            \n",
    "            # Search for recent matches involving these teams\n",
    "            home_matches = fotmob.read_team_match_stats(team=home_team, stat_type=\"match\")\n",
    "            away_matches = fotmob.read_team_match_stats(team=away_team, stat_type=\"match\")\n",
    "            \n",
    "            # Find the match between these two teams\n",
    "            recent_match = None\n",
    "            if not home_matches.empty and not away_matches.empty:\n",
    "                # Look for recent head-to-head match\n",
    "                for idx, match in home_matches.iterrows():\n",
    "                    if away_team.lower() in str(match).lower():\n",
    "                        recent_match = match\n",
    "                        break\n",
    "            \n",
    "            if recent_match is not None:\n",
    "                # Extract basic stats (structure depends on FotMob data format)\n",
    "                stats_data['attempts_home'] = getattr(recent_match, 'shots_home', 0) or 0\n",
    "                stats_data['attempts_away'] = getattr(recent_match, 'shots_away', 0) or 0\n",
    "                stats_data['on_target_home'] = getattr(recent_match, 'shots_on_target_home', 0) or 0\n",
    "                stats_data['on_target_away'] = getattr(recent_match, 'shots_on_target_away', 0) or 0\n",
    "                stats_data['corners_home'] = getattr(recent_match, 'corners_home', 0) or 0\n",
    "                stats_data['corners_away'] = getattr(recent_match, 'corners_away', 0) or 0\n",
    "                \n",
    "                print(\"‚úÖ Extracted stats from FotMob\")\n",
    "                return stats_data\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è FotMob failed: {e}\")\n",
    "        \n",
    "        # Try SofaScore as fallback\n",
    "        try:\n",
    "            sofascore = sd.Sofascore()\n",
    "            \n",
    "            # Get recent matches for both teams\n",
    "            home_stats = sofascore.read_team_match_stats(team=home_team)\n",
    "            away_stats = sofascore.read_team_match_stats(team=away_team)\n",
    "            \n",
    "            # Process the data similar to FotMob\n",
    "            if not home_stats.empty or not away_stats.empty:\n",
    "                print(\"‚úÖ Extracted stats from SofaScore via SoccerData\")\n",
    "                return stats_data\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è SofaScore failed: {e}\")\n",
    "        \n",
    "        # Try FBref for team statistics (season-long stats)\n",
    "        try:\n",
    "            fbref = sd.FBref()\n",
    "            \n",
    "            # Get team stats for the season\n",
    "            if league:\n",
    "                team_stats = fbref.read_team_season_stats(stat_type=\"standard\")\n",
    "                \n",
    "                # Extract relevant team stats\n",
    "                home_team_stats = team_stats[team_stats.index.get_level_values('team').str.contains(home_team, case=False, na=False)]\n",
    "                away_team_stats = team_stats[team_stats.index.get_level_values('team').str.contains(away_team, case=False, na=False)]\n",
    "                \n",
    "                if not home_team_stats.empty and not away_team_stats.empty:\n",
    "                    # Extract season averages as proxy\n",
    "                    stats_data['l5g_home_gf'] = int(home_team_stats['goals_for'].iloc[0] / 5) if 'goals_for' in home_team_stats.columns else 0\n",
    "                    stats_data['l5g_home_ga'] = int(home_team_stats['goals_against'].iloc[0] / 5) if 'goals_against' in home_team_stats.columns else 0\n",
    "                    stats_data['l5g_away_gf'] = int(away_team_stats['goals_for'].iloc[0] / 5) if 'goals_for' in away_team_stats.columns else 0\n",
    "                    stats_data['l5g_away_ga'] = int(away_team_stats['goals_against'].iloc[0] / 5) if 'goals_against' in away_team_stats.columns else 0\n",
    "                    \n",
    "                    print(\"‚úÖ Extracted stats from FBref\")\n",
    "                    return stats_data\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è FBref failed: {e}\")\n",
    "        \n",
    "        print(\"‚ö†Ô∏è No stats found via SoccerData\")\n",
    "        return stats_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå SoccerData extraction failed: {e}\")\n",
    "        return stats_data\n",
    "    \n",
    "\n",
    "def update_csv_with_soccerdata(csv_filename, league=None):\n",
    "    \"\"\"\n",
    "    Update existing CSV file with SoccerData statistics (alternative to manual scraping)\n",
    "    \"\"\"\n",
    "    if not SOCCERDATA_AVAILABLE:\n",
    "        print(\"‚ùå SoccerData library not available. Install with: pip install soccerdata\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Read existing CSV\n",
    "        df = pd.read_csv(csv_filename)\n",
    "        print(f\"üìñ Reading {len(df)} matches from {csv_filename}\")\n",
    "        \n",
    "        # Add new columns if they don't exist\n",
    "        new_columns = ['attempts_home', 'attempts_away', 'on_target_home', 'on_target_away', \n",
    "                      'corners_home', 'corners_away', 'l5g_home_gf', 'l5g_home_ga', \n",
    "                      'l5g_away_gf', 'l5g_away_ga', 'possession_home', 'possession_away',\n",
    "                      'passes_home', 'passes_away', 'data_source']\n",
    "        \n",
    "        for col in new_columns:\n",
    "            if col not in df.columns:\n",
    "                df[col] = 0\n",
    "        \n",
    "        # Process each match using SoccerData\n",
    "        for index, row in df.iterrows():\n",
    "            home_team = row['home-team']\n",
    "            away_team = row['away-team']\n",
    "            title = row['title']\n",
    "            \n",
    "            print(f\"üîç Processing with SoccerData: {title}\")\n",
    "            \n",
    "            # Get stats using SoccerData\n",
    "            stats = get_history_stats_soccerdata(home_team, away_team, league)\n",
    "            \n",
    "            if stats:\n",
    "                # Update DataFrame with stats\n",
    "                for stat_key, stat_value in stats.items():\n",
    "                    if stat_key in df.columns:\n",
    "                        df.at[index, stat_key] = stat_value\n",
    "                \n",
    "                print(f\"‚úÖ Updated stats for {title}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è No stats found for {title}\")\n",
    "            \n",
    "            # Add delay to be respectful\n",
    "            time.sleep(1)\n",
    "        \n",
    "        # Save updated CSV\n",
    "        updated_filename = csv_filename.replace('.csv', '_with_soccerdata.csv')\n",
    "        df.to_csv(updated_filename, index=False)\n",
    "        \n",
    "        print(f\"üíæ Updated CSV saved as: {updated_filename}\")\n",
    "        print(f\"üìä Processed {len(df)} matches with SoccerData\")\n",
    "        \n",
    "        return updated_filename\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error updating CSV with SoccerData: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def display_results(filename=None):\n",
    "    \"\"\"\n",
    "    Read and display the CSV file contents\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if filename is None:\n",
    "            print(\"‚ùå No filename provided\")\n",
    "            return None\n",
    "            \n",
    "        df = pd.read_csv(filename)\n",
    "        print(f\"\\nüìã Contents of {filename}:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(df.to_string(index=False))\n",
    "        print(f\"\\nüìà Dataset Info:\")\n",
    "        print(f\"   - Shape: {df.shape}\")\n",
    "        print(f\"   - Columns: {list(df.columns)}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå File {filename} not found\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3107d1",
   "metadata": {},
   "source": [
    "### Scrape fresh data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b042bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Fetching data...\n",
      "üõ†Ô∏è Initializing browser...\n",
      "üéÆ Found 0 ongoing events\n",
      "\n",
      "üìä Summary:\n",
      "   - HT: 0, H1: 0, H2: 0\n",
      "   - 0 at HT events: 0\n"
     ]
    }
   ],
   "source": [
    "matches_data = scrape_sb_live()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Starting sb Scraper\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Step 1: Scrape the website\n",
    "matches_data = scrape_sb_live()\n",
    "\n",
    "if matches_data:\n",
    "    # Step 2: Save to CSV with timestamp\n",
    "    success, csv_filename = save_to_csv(matches_data)\n",
    "    if success and csv_filename:\n",
    "        # Step 3: Read and display results\n",
    "        df = display_results(csv_filename)\n",
    "        \n",
    "        if df is not None and not df.empty:\n",
    "            print(f\"\\nüéâ Successfully processed {len(df)} matches with 0 HT goals!\")\n",
    "            print(f\"üìÅ File saved as: {csv_filename}\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è No matches found with 0 total goals at halftime\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No data extracted. Please check the website structure or network connection.\")\n",
    "\n",
    "print(\"\\n‚úÖ Script execution completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad12135",
   "metadata": {},
   "source": [
    "### Save to CSV with timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc0d6ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No data to save\n",
      "‚ùå No filename provided\n"
     ]
    }
   ],
   "source": [
    "success, filename = save_to_csv(matches_data)\n",
    "\n",
    "# Display results using returned filename\"\n",
    "df = display_results(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f84de0",
   "metadata": {},
   "source": [
    "### Extract stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa13d649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "743bdafe",
   "metadata": {},
   "source": [
    "### Update csv with extracted stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036e3ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_file = update_csv_with_soccerdata(filename)\n",
    "final_df = display_results(updated_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
