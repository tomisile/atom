{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69fbcdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (349, 15)\n",
      "\n",
      "Column names:\n",
      "['date', 'log_time', 'tournament', 'title', 'home-team', 'away-team', 'pre-match_odds_home', 'pre-match_odds_draw', 'pre-match_odds_away', 'home_ht_goals', 'away_ht_goals', 'ht_goals', 'home_ft_goals', 'away_ft_goals', 'ft_goals']\n",
      "\n",
      "First few rows:\n",
      "       date log_time tournament                                title  \\\n",
      "0  07-09-25    09:25        NaN     Tuen Mun SA vs Wong Tai Sin DRSC   \n",
      "1  07-09-25    09:25        NaN  St. Joseph's Football Club vs Qi Yi   \n",
      "2  07-09-25    09:25        NaN                 Tsun Tat vs Ornament   \n",
      "3  07-09-25    09:30        NaN              Yuen Long FC vs Sha Tin   \n",
      "4  07-09-25    09:52        NaN            Poland SRL vs Finland SRL   \n",
      "\n",
      "                    home-team          away-team  pre-match_odds_home  \\\n",
      "0                 Tuen Mun SA  Wong Tai Sin DRSC                  NaN   \n",
      "1  St. Joseph's Football Club              Qi Yi                  NaN   \n",
      "2                    Tsun Tat           Ornament                  NaN   \n",
      "3                Yuen Long FC            Sha Tin                  NaN   \n",
      "4                  Poland SRL        Finland SRL                  NaN   \n",
      "\n",
      "   pre-match_odds_draw  pre-match_odds_away  home_ht_goals  away_ht_goals  \\\n",
      "0                  NaN                  NaN              0              1   \n",
      "1                  NaN                  NaN              0              0   \n",
      "2                  NaN                  NaN              0              0   \n",
      "3                  NaN                  NaN              0              0   \n",
      "4                  NaN                  NaN              0              0   \n",
      "\n",
      "   ht_goals  home_ft_goals  away_ft_goals  ft_goals  \n",
      "0         1            1.0            4.0       5.0  \n",
      "1         0            1.0            1.0       2.0  \n",
      "2         0            2.0            1.0       3.0  \n",
      "3         0            0.0            3.0       3.0  \n",
      "4         0            0.0            0.0       0.0  \n",
      "\n",
      "Data types:\n",
      "date                    object\n",
      "log_time                object\n",
      "tournament              object\n",
      "title                   object\n",
      "home-team               object\n",
      "away-team               object\n",
      "pre-match_odds_home    float64\n",
      "pre-match_odds_draw    float64\n",
      "pre-match_odds_away    float64\n",
      "home_ht_goals            int64\n",
      "away_ht_goals            int64\n",
      "ht_goals                 int64\n",
      "home_ft_goals          float64\n",
      "away_ft_goals          float64\n",
      "ft_goals               float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "date                     0\n",
      "log_time                 0\n",
      "tournament             107\n",
      "title                    0\n",
      "home-team                0\n",
      "away-team                0\n",
      "pre-match_odds_home    107\n",
      "pre-match_odds_draw    107\n",
      "pre-match_odds_away    107\n",
      "home_ht_goals            0\n",
      "away_ht_goals            0\n",
      "ht_goals                 0\n",
      "home_ft_goals            6\n",
      "away_ft_goals            6\n",
      "ft_goals                 6\n",
      "dtype: int64\n",
      "\n",
      "Data after cleaning: 343 rows\n",
      "\n",
      "Matches with 0 HT goals: 155\n",
      "Of these, 119 (76.77%) had ≥1 FT goals\n",
      "\n",
      "Matches with 1 HT goal: 188\n",
      "Of these, 154 (81.91%) had ≥2 FT goals\n",
      "\n",
      "HT=0 model: 155 samples, 10 features\n",
      "HT=1 model: 188 samples, 10 features\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomi/miniconda3/envs/tfenv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  bias_constraint=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.3642 - loss: 0.7393 - val_accuracy: 0.5600 - val_loss: 0.6867\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5987 - loss: 0.6765 - val_accuracy: 0.7600 - val_loss: 0.6420\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6935 - loss: 0.6345 - val_accuracy: 0.7200 - val_loss: 0.6100\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7614 - loss: 0.6224 - val_accuracy: 0.7600 - val_loss: 0.5891\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7468 - loss: 0.5924 - val_accuracy: 0.7600 - val_loss: 0.5757\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7717 - loss: 0.5675 - val_accuracy: 0.7600 - val_loss: 0.5653\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7862 - loss: 0.5244 - val_accuracy: 0.7600 - val_loss: 0.5575\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7592 - loss: 0.5764 - val_accuracy: 0.7600 - val_loss: 0.5539\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7623 - loss: 0.5531 - val_accuracy: 0.7600 - val_loss: 0.5532\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7717 - loss: 0.5363 - val_accuracy: 0.7600 - val_loss: 0.5555\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7581 - loss: 0.5304 - val_accuracy: 0.7600 - val_loss: 0.5582\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7467 - loss: 0.5653 - val_accuracy: 0.7600 - val_loss: 0.5604\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7467 - loss: 0.5492 - val_accuracy: 0.7600 - val_loss: 0.5632\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7487 - loss: 0.5457 - val_accuracy: 0.7600 - val_loss: 0.5655\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7737 - loss: 0.5275 - val_accuracy: 0.7600 - val_loss: 0.5672\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7904 - loss: 0.4897 - val_accuracy: 0.7600 - val_loss: 0.5707\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7623 - loss: 0.4904 - val_accuracy: 0.7600 - val_loss: 0.5749\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7717 - loss: 0.4752 - val_accuracy: 0.7600 - val_loss: 0.5798\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7373 - loss: 0.5636 - val_accuracy: 0.7600 - val_loss: 0.5846\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7821 - loss: 0.4679 - val_accuracy: 0.7600 - val_loss: 0.5872\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7769 - loss: 0.4732 - val_accuracy: 0.7600 - val_loss: 0.5826\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7592 - loss: 0.5004 - val_accuracy: 0.7600 - val_loss: 0.5807\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7769 - loss: 0.4937 - val_accuracy: 0.7600 - val_loss: 0.5803\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7498 - loss: 0.4855 - val_accuracy: 0.7600 - val_loss: 0.5830\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7560 - loss: 0.4749 - val_accuracy: 0.7600 - val_loss: 0.5883\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7644 - loss: 0.4658 - val_accuracy: 0.7600 - val_loss: 0.5945\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7644 - loss: 0.4768 - val_accuracy: 0.7600 - val_loss: 0.6002\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7467 - loss: 0.4882 - val_accuracy: 0.7600 - val_loss: 0.6068\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7758 - loss: 0.4856 - val_accuracy: 0.7600 - val_loss: 0.6101\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7498 - loss: 0.4763 - val_accuracy: 0.7600 - val_loss: 0.6096\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7331 - loss: 0.5247 - val_accuracy: 0.7600 - val_loss: 0.6094\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7675 - loss: 0.5000 - val_accuracy: 0.7600 - val_loss: 0.6057\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7425 - loss: 0.5243 - val_accuracy: 0.7600 - val_loss: 0.5985\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7799 - loss: 0.4608 - val_accuracy: 0.7600 - val_loss: 0.5962\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7831 - loss: 0.4490 - val_accuracy: 0.7600 - val_loss: 0.5984\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7612 - loss: 0.4690 - val_accuracy: 0.7600 - val_loss: 0.6031\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7779 - loss: 0.4383 - val_accuracy: 0.7600 - val_loss: 0.6091\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7924 - loss: 0.4406 - val_accuracy: 0.7600 - val_loss: 0.6160\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7590 - loss: 0.4653 - val_accuracy: 0.7600 - val_loss: 0.6246\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7778 - loss: 0.4741 - val_accuracy: 0.7200 - val_loss: 0.6320\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7717 - loss: 0.4545 - val_accuracy: 0.7200 - val_loss: 0.6387\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7560 - loss: 0.4439 - val_accuracy: 0.7600 - val_loss: 0.6466\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7777 - loss: 0.4465 - val_accuracy: 0.7600 - val_loss: 0.6552\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8214 - loss: 0.4097 - val_accuracy: 0.7600 - val_loss: 0.6655\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7986 - loss: 0.4385 - val_accuracy: 0.7600 - val_loss: 0.6733\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7747 - loss: 0.4276 - val_accuracy: 0.7200 - val_loss: 0.6781\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7839 - loss: 0.4533 - val_accuracy: 0.7200 - val_loss: 0.6813\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7675 - loss: 0.5006 - val_accuracy: 0.7600 - val_loss: 0.6796\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7717 - loss: 0.4456 - val_accuracy: 0.7600 - val_loss: 0.6784\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7705 - loss: 0.4529 - val_accuracy: 0.7600 - val_loss: 0.6783\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7467 - loss: 0.4803 - val_accuracy: 0.7600 - val_loss: 0.6775\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7736 - loss: 0.4895 - val_accuracy: 0.7200 - val_loss: 0.6760\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7870 - loss: 0.4609 - val_accuracy: 0.7200 - val_loss: 0.6699\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7984 - loss: 0.4205 - val_accuracy: 0.7600 - val_loss: 0.6665\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7912 - loss: 0.4600 - val_accuracy: 0.7600 - val_loss: 0.6599\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7933 - loss: 0.4088 - val_accuracy: 0.7600 - val_loss: 0.6563\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8347 - loss: 0.3965 - val_accuracy: 0.7600 - val_loss: 0.6529\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7839 - loss: 0.4826 - val_accuracy: 0.7600 - val_loss: 0.6458\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7735 - loss: 0.4479 - val_accuracy: 0.7600 - val_loss: 0.6419\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7645 - loss: 0.4180 - val_accuracy: 0.8000 - val_loss: 0.6382\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8107 - loss: 0.4739 - val_accuracy: 0.8000 - val_loss: 0.6258\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7715 - loss: 0.4769 - val_accuracy: 0.8000 - val_loss: 0.6220\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8119 - loss: 0.4278 - val_accuracy: 0.8000 - val_loss: 0.6190\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7714 - loss: 0.4640 - val_accuracy: 0.8000 - val_loss: 0.6217\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7869 - loss: 0.4459 - val_accuracy: 0.8000 - val_loss: 0.6264\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7343 - loss: 0.4564 - val_accuracy: 0.8000 - val_loss: 0.6327\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8037 - loss: 0.3945 - val_accuracy: 0.8000 - val_loss: 0.6380\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7706 - loss: 0.4299 - val_accuracy: 0.8000 - val_loss: 0.6398\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7985 - loss: 0.4165 - val_accuracy: 0.8000 - val_loss: 0.6422\n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7922 - loss: 0.3939 - val_accuracy: 0.8000 - val_loss: 0.6473\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7800 - loss: 0.4529 - val_accuracy: 0.7600 - val_loss: 0.6544\n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8012 - loss: 0.4188 - val_accuracy: 0.8000 - val_loss: 0.6639\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7921 - loss: 0.4362 - val_accuracy: 0.8000 - val_loss: 0.6654\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7924 - loss: 0.4142 - val_accuracy: 0.7200 - val_loss: 0.6672\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7662 - loss: 0.4176 - val_accuracy: 0.7200 - val_loss: 0.6683\n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7683 - loss: 0.4223 - val_accuracy: 0.7600 - val_loss: 0.6695\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7425 - loss: 0.4544 - val_accuracy: 0.8000 - val_loss: 0.6701\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7870 - loss: 0.3657 - val_accuracy: 0.8000 - val_loss: 0.6730\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7932 - loss: 0.4161 - val_accuracy: 0.8000 - val_loss: 0.6824\n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8006 - loss: 0.3755 - val_accuracy: 0.7600 - val_loss: 0.6921\n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8004 - loss: 0.4172 - val_accuracy: 0.7600 - val_loss: 0.6946\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7881 - loss: 0.4186 - val_accuracy: 0.7600 - val_loss: 0.6936\n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7589 - loss: 0.4431 - val_accuracy: 0.7600 - val_loss: 0.6936\n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7489 - loss: 0.4079 - val_accuracy: 0.7200 - val_loss: 0.6979\n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7922 - loss: 0.3920 - val_accuracy: 0.8000 - val_loss: 0.7061\n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7682 - loss: 0.4421 - val_accuracy: 0.8000 - val_loss: 0.7135\n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8085 - loss: 0.4509 - val_accuracy: 0.7600 - val_loss: 0.7227\n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7529 - loss: 0.4247 - val_accuracy: 0.7200 - val_loss: 0.7413\n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7932 - loss: 0.3970 - val_accuracy: 0.6800 - val_loss: 0.7611\n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7735 - loss: 0.3773 - val_accuracy: 0.6800 - val_loss: 0.7789\n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7312 - loss: 0.4686 - val_accuracy: 0.6800 - val_loss: 0.7895\n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8049 - loss: 0.3854 - val_accuracy: 0.7200 - val_loss: 0.8044\n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8023 - loss: 0.4472 - val_accuracy: 0.6800 - val_loss: 0.8110\n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8086 - loss: 0.4135 - val_accuracy: 0.6800 - val_loss: 0.8154\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8584 - loss: 0.3298 - val_accuracy: 0.6400 - val_loss: 0.8199\n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8131 - loss: 0.3697 - val_accuracy: 0.6800 - val_loss: 0.8177\n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8261 - loss: 0.4049 - val_accuracy: 0.6800 - val_loss: 0.8072\n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8768 - loss: 0.3682 - val_accuracy: 0.6800 - val_loss: 0.7933\n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7899 - loss: 0.4238 - val_accuracy: 0.6800 - val_loss: 0.7811\n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8325 - loss: 0.3638 - val_accuracy: 0.6400 - val_loss: 0.7842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "=== HT=0 Model Results ===\n",
      "Accuracy: 0.7097\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           1       0.78      0.88      0.82        24\n",
      "\n",
      "    accuracy                           0.71        31\n",
      "   macro avg       0.51      0.51      0.50        31\n",
      "weighted avg       0.66      0.71      0.68        31\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomi/miniconda3/envs/tfenv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  bias_constraint=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.6523 - loss: 0.6525 - val_accuracy: 0.9333 - val_loss: 0.5193\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7990 - loss: 0.5580 - val_accuracy: 0.9333 - val_loss: 0.4300\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7927 - loss: 0.5415 - val_accuracy: 0.9333 - val_loss: 0.3690\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7750 - loss: 0.5406 - val_accuracy: 0.9333 - val_loss: 0.3373\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8010 - loss: 0.5112 - val_accuracy: 0.9333 - val_loss: 0.3164\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7625 - loss: 0.5432 - val_accuracy: 0.9333 - val_loss: 0.3073\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8188 - loss: 0.4793 - val_accuracy: 0.9333 - val_loss: 0.3037\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7688 - loss: 0.5694 - val_accuracy: 0.9333 - val_loss: 0.3118\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7729 - loss: 0.5211 - val_accuracy: 0.9333 - val_loss: 0.3232\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7698 - loss: 0.5169 - val_accuracy: 0.9333 - val_loss: 0.3344\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8156 - loss: 0.4723 - val_accuracy: 0.9333 - val_loss: 0.3406\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8177 - loss: 0.4650 - val_accuracy: 0.9333 - val_loss: 0.3486\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8042 - loss: 0.4582 - val_accuracy: 0.9333 - val_loss: 0.3548\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7917 - loss: 0.4818 - val_accuracy: 0.9333 - val_loss: 0.3594\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7792 - loss: 0.5246 - val_accuracy: 0.9333 - val_loss: 0.3631\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8104 - loss: 0.4826 - val_accuracy: 0.9333 - val_loss: 0.3617\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7896 - loss: 0.4638 - val_accuracy: 0.9333 - val_loss: 0.3606\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7667 - loss: 0.4787 - val_accuracy: 0.9333 - val_loss: 0.3586\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7906 - loss: 0.4838 - val_accuracy: 0.9333 - val_loss: 0.3558\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8083 - loss: 0.4586 - val_accuracy: 0.9333 - val_loss: 0.3539\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7792 - loss: 0.4945 - val_accuracy: 0.9333 - val_loss: 0.3519\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7792 - loss: 0.4963 - val_accuracy: 0.9333 - val_loss: 0.3481\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8198 - loss: 0.4189 - val_accuracy: 0.9333 - val_loss: 0.3407\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8044 - loss: 0.4286 - val_accuracy: 0.9333 - val_loss: 0.3410\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8031 - loss: 0.4738 - val_accuracy: 0.9333 - val_loss: 0.3419\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7875 - loss: 0.4879 - val_accuracy: 0.9333 - val_loss: 0.3498\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8063 - loss: 0.4484 - val_accuracy: 0.9333 - val_loss: 0.3532\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8063 - loss: 0.4441 - val_accuracy: 0.9333 - val_loss: 0.3549\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7906 - loss: 0.4425 - val_accuracy: 0.9333 - val_loss: 0.3553\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8181 - loss: 0.4531 - val_accuracy: 0.9333 - val_loss: 0.3565\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7933 - loss: 0.4494 - val_accuracy: 0.9333 - val_loss: 0.3562\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7802 - loss: 0.4467 - val_accuracy: 0.9333 - val_loss: 0.3605\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7721 - loss: 0.4667 - val_accuracy: 0.9333 - val_loss: 0.3635\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7717 - loss: 0.4496 - val_accuracy: 0.9333 - val_loss: 0.3608\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7919 - loss: 0.4413 - val_accuracy: 0.9333 - val_loss: 0.3586\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7344 - loss: 0.5092 - val_accuracy: 0.9333 - val_loss: 0.3610\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7981 - loss: 0.4277 - val_accuracy: 0.9333 - val_loss: 0.3502\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8085 - loss: 0.3992 - val_accuracy: 0.9333 - val_loss: 0.3453\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8200 - loss: 0.4277 - val_accuracy: 0.9333 - val_loss: 0.3478\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8210 - loss: 0.4103 - val_accuracy: 0.9333 - val_loss: 0.3512\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8221 - loss: 0.4265 - val_accuracy: 0.9333 - val_loss: 0.3592\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7575 - loss: 0.4507 - val_accuracy: 0.9333 - val_loss: 0.3612\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7971 - loss: 0.4281 - val_accuracy: 0.9333 - val_loss: 0.3562\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7667 - loss: 0.4537 - val_accuracy: 0.9333 - val_loss: 0.3520\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8171 - loss: 0.4222 - val_accuracy: 0.9333 - val_loss: 0.3435\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8348 - loss: 0.3810 - val_accuracy: 0.9333 - val_loss: 0.3422\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8210 - loss: 0.3924 - val_accuracy: 0.9333 - val_loss: 0.3430\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7752 - loss: 0.4416 - val_accuracy: 0.9333 - val_loss: 0.3464\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7883 - loss: 0.4192 - val_accuracy: 0.9333 - val_loss: 0.3477\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8085 - loss: 0.4300 - val_accuracy: 0.9333 - val_loss: 0.3524\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8029 - loss: 0.4053 - val_accuracy: 0.9333 - val_loss: 0.3533\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7927 - loss: 0.4087 - val_accuracy: 0.8667 - val_loss: 0.3590\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7958 - loss: 0.4298 - val_accuracy: 0.8667 - val_loss: 0.3635\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7969 - loss: 0.4101 - val_accuracy: 0.8667 - val_loss: 0.3621\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7994 - loss: 0.4380 - val_accuracy: 0.8667 - val_loss: 0.3615\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7910 - loss: 0.4091 - val_accuracy: 0.8667 - val_loss: 0.3515\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8306 - loss: 0.3907 - val_accuracy: 0.8667 - val_loss: 0.3474\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8015 - loss: 0.4061 - val_accuracy: 0.9333 - val_loss: 0.3410\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7819 - loss: 0.4147 - val_accuracy: 0.9333 - val_loss: 0.3456\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7658 - loss: 0.4598 - val_accuracy: 0.9333 - val_loss: 0.3463\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8492 - loss: 0.3755 - val_accuracy: 0.9333 - val_loss: 0.3493\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8454 - loss: 0.3650 - val_accuracy: 0.8667 - val_loss: 0.3595\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7875 - loss: 0.4142 - val_accuracy: 0.8667 - val_loss: 0.3675\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7488 - loss: 0.4334 - val_accuracy: 0.8667 - val_loss: 0.3751\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7806 - loss: 0.4185 - val_accuracy: 0.8667 - val_loss: 0.3707\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8054 - loss: 0.3918 - val_accuracy: 0.8667 - val_loss: 0.3554\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8148 - loss: 0.3875 - val_accuracy: 0.8667 - val_loss: 0.3446\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7488 - loss: 0.4436 - val_accuracy: 0.9000 - val_loss: 0.3411\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7952 - loss: 0.3765 - val_accuracy: 0.8667 - val_loss: 0.3433\n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7896 - loss: 0.3986 - val_accuracy: 0.8667 - val_loss: 0.3456\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8213 - loss: 0.3912 - val_accuracy: 0.8667 - val_loss: 0.3510\n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8131 - loss: 0.3721 - val_accuracy: 0.8667 - val_loss: 0.3567\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7554 - loss: 0.4528 - val_accuracy: 0.8667 - val_loss: 0.3654\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8410 - loss: 0.3816 - val_accuracy: 0.8667 - val_loss: 0.3628\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8425 - loss: 0.3559 - val_accuracy: 0.8667 - val_loss: 0.3624\n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8206 - loss: 0.3773 - val_accuracy: 0.8667 - val_loss: 0.3523\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8581 - loss: 0.3250 - val_accuracy: 0.8667 - val_loss: 0.3391\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8104 - loss: 0.3863 - val_accuracy: 0.8667 - val_loss: 0.3422\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8210 - loss: 0.3616 - val_accuracy: 0.8667 - val_loss: 0.3444\n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8240 - loss: 0.3793 - val_accuracy: 0.8333 - val_loss: 0.3518\n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7865 - loss: 0.3425 - val_accuracy: 0.8333 - val_loss: 0.3548\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7700 - loss: 0.4397 - val_accuracy: 0.8333 - val_loss: 0.3592\n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8035 - loss: 0.3663 - val_accuracy: 0.8333 - val_loss: 0.3633\n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8213 - loss: 0.3996 - val_accuracy: 0.8333 - val_loss: 0.3676\n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8017 - loss: 0.3787 - val_accuracy: 0.8333 - val_loss: 0.3659\n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8365 - loss: 0.3730 - val_accuracy: 0.8333 - val_loss: 0.3691\n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8210 - loss: 0.3766 - val_accuracy: 0.8333 - val_loss: 0.3644\n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7960 - loss: 0.3939 - val_accuracy: 0.8333 - val_loss: 0.3753\n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8215 - loss: 0.3547 - val_accuracy: 0.8333 - val_loss: 0.3782\n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7919 - loss: 0.3905 - val_accuracy: 0.8333 - val_loss: 0.3874\n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8202 - loss: 0.3685 - val_accuracy: 0.8333 - val_loss: 0.3792\n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8350 - loss: 0.3556 - val_accuracy: 0.8333 - val_loss: 0.3762\n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8135 - loss: 0.3469 - val_accuracy: 0.8667 - val_loss: 0.3729\n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7833 - loss: 0.4180 - val_accuracy: 0.8667 - val_loss: 0.3791\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8192 - loss: 0.3357 - val_accuracy: 0.8667 - val_loss: 0.3797\n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8369 - loss: 0.3640 - val_accuracy: 0.9000 - val_loss: 0.3648\n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8525 - loss: 0.3176 - val_accuracy: 0.9000 - val_loss: 0.3543\n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8487 - loss: 0.3267 - val_accuracy: 0.9000 - val_loss: 0.3611\n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8000 - loss: 0.3644 - val_accuracy: 0.8667 - val_loss: 0.3842\n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8250 - loss: 0.3575 - val_accuracy: 0.8667 - val_loss: 0.4031\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f64a44c9300> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/stepWARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f64a44c9300> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\n",
      "=== HT=1 Model Results ===\n",
      "Accuracy: 0.7895\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           1       0.83      0.94      0.88        31\n",
      "\n",
      "    accuracy                           0.79        38\n",
      "   macro avg       0.58      0.54      0.54        38\n",
      "weighted avg       0.74      0.79      0.75        38\n",
      "\n",
      "\n",
      "==================================================\n",
      "HIGH-CONFIDENCE ANALYSIS - HT=0 MODEL\n",
      "\n",
      "High Confidence Predictions (>90% or <10%):\n",
      "Number of high-confidence predictions: 14\n",
      "Percentage of total: 45.16%\n",
      "Accuracy on high-confidence predictions: 0.7857\n",
      "\n",
      "==================================================\n",
      "HIGH-CONFIDENCE ANALYSIS - HT=1 MODEL\n",
      "\n",
      "High Confidence Predictions (>90% or <10%):\n",
      "Number of high-confidence predictions: 12\n",
      "Percentage of total: 31.58%\n",
      "Accuracy on high-confidence predictions: 0.8333\n",
      "\n",
      "==================================================\n",
      "FEATURE IMPORTANCE - HT=0 MODEL\n",
      "\n",
      "Feature Importance (by accuracy drop when shuffled):\n",
      "draw_prob_norm: -0.0968\n",
      "tournament_encoded: -0.0323\n",
      "away_team_encoded: -0.0323\n",
      "home_team_encoded: 0.0000\n",
      "home_prob_norm: 0.0000\n",
      "away_prob_norm: 0.0000\n",
      "team_strength_diff: 0.0000\n",
      "home_ht_goals: 0.0000\n",
      "away_ht_goals: 0.0000\n",
      "ht_goal_diff: 0.0000\n",
      "\n",
      "==================================================\n",
      "FEATURE IMPORTANCE - HT=1 MODEL\n",
      "\n",
      "Feature Importance (by accuracy drop when shuffled):\n",
      "draw_prob_norm: 0.0789\n",
      "team_strength_diff: 0.0526\n",
      "away_team_encoded: 0.0263\n",
      "away_prob_norm: 0.0263\n",
      "home_ht_goals: 0.0263\n",
      "tournament_encoded: -0.0263\n",
      "away_ht_goals: -0.0263\n",
      "ht_goal_diff: -0.0263\n",
      "home_team_encoded: 0.0000\n",
      "home_prob_norm: 0.0000\n",
      "\n",
      "================================================================================\n",
      "SUMMARY AND RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "ANALYSIS SUMMARY:\n",
      "1. The model attempts to predict goal probabilities based on available features\n",
      "2. High-confidence predictions (>90% certainty) are analyzed separately\n",
      "3. Feature importance shows which variables matter most\n",
      "\n",
      "ACHIEVING 99% ACCURACY - REALISTIC ASSESSMENT:\n",
      "- 99% accuracy on ALL predictions is extremely difficult with this data\n",
      "- However, 99% accuracy on a SUBSET of high-confidence predictions is more feasible\n",
      "- The key is identifying which games to predict vs. which to skip\n",
      "\n",
      "STRATEGY FOR HIGH-CONFIDENCE PREDICTIONS:\n",
      "1. Focus on matches where the model is >95% confident\n",
      "2. This might be 10-20% of total matches, but with very high accuracy\n",
      "3. Use ensemble methods and additional features for better confidence estimation\n",
      "\n",
      "ADDITIONAL FEATURES THAT COULD IMPROVE ACCURACY:\n",
      "(All easily accessible)\n",
      "\n",
      "1. TEAM FORM FEATURES:\n",
      "   - Last 5 games: goals scored/conceded per team\n",
      "   - Recent head-to-head record\n",
      "   - Home/away form separately\n",
      "\n",
      "2. LEAGUE-SPECIFIC FEATURES:\n",
      "   - Average goals per game in the league\n",
      "   - League defensive/offensive strength ratings\n",
      "   - Season stage (early/mid/late season affects motivation)\n",
      "\n",
      "3. TEMPORAL FEATURES:\n",
      "   - Day of week (weekend vs. weekday affects performance)\n",
      "   - Month/season (weather effects, player fitness)\n",
      "   - Days since last match (rest effects)\n",
      "\n",
      "4. BETTING MARKET FEATURES:\n",
      "   - Over/Under 2.5 goals odds\n",
      "   - Both teams to score odds\n",
      "   - Asian handicap lines\n",
      "\n",
      "5. TEAM STATISTICS:\n",
      "   - League position/points\n",
      "   - Goals for/against ratios\n",
      "   - Average possession percentage\n",
      "\n",
      "6. MATCH CONTEXT:\n",
      "   - Derby matches (local rivals)\n",
      "   - Cup vs. league matches\n",
      "   - Importance of match (relegation/promotion battles)\n",
      "\n",
      "IMPLEMENTATION STRATEGY:\n",
      "1. Start with current model to identify high-confidence predictions\n",
      "2. Add team form features (most impactful)\n",
      "3. Include league context and betting odds\n",
      "4. Use ensemble of multiple models\n",
      "5. Implement strict confidence thresholds (predict only top 10-20% most certain)\n",
      "\n",
      "This approach could realistically achieve 90-99% accuracy on the subset of matches \n",
      "where the model is most confident, while avoiding predictions on uncertain matches.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Football Goals Prediction Model\n",
    "# Predicting probability of goals in second half based on first half performance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Read the data\n",
    "# Assuming the CSV file is saved as 'football_data.csv'\n",
    "df = pd.read_csv('final_db.csv')\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Basic data exploration\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Clean and prepare the data\n",
    "# Remove rows with missing ft_goals or ht_goals\n",
    "df_clean = df.dropna(subset=['ft_goals', 'ht_goals'])\n",
    "\n",
    "print(f\"\\nData after cleaning: {df_clean.shape[0]} rows\")\n",
    "\n",
    "# Create target variables based on your requirements\n",
    "# Target 1: For matches with 0 goals at HT, will there be ≥1 goal at FT?\n",
    "# Target 2: For matches with 1 goal at HT, will there be ≥2 goals at FT?\n",
    "\n",
    "df_ht0 = df_clean[df_clean['ht_goals'] == 0].copy()\n",
    "df_ht1 = df_clean[df_clean['ht_goals'] == 1].copy()\n",
    "\n",
    "# Create binary targets\n",
    "df_ht0['target'] = (df_ht0['ft_goals'] >= 1).astype(int)\n",
    "df_ht1['target'] = (df_ht1['ft_goals'] >= 2).astype(int)\n",
    "\n",
    "print(f\"\\nMatches with 0 HT goals: {len(df_ht0)}\")\n",
    "print(f\"Of these, {df_ht0['target'].sum()} ({df_ht0['target'].mean():.2%}) had ≥1 FT goals\")\n",
    "\n",
    "print(f\"\\nMatches with 1 HT goal: {len(df_ht1)}\")\n",
    "print(f\"Of these, {df_ht1['target'].sum()} ({df_ht1['target'].mean():.2%}) had ≥2 FT goals\")\n",
    "\n",
    "# Feature engineering function\n",
    "def create_features(df):\n",
    "    features_df = df.copy()\n",
    "    \n",
    "    # Time-based features\n",
    "    # features_df['log_time'] = pd.to_datetime(features_df['log_time'], format='%H:%M', errors='coerce')\n",
    "    # features_df['hour'] = features_df['log_time'].dt.hour\n",
    "    # features_df['minute'] = features_df['log_time'].dt.minute\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le_tournament = LabelEncoder()\n",
    "    le_home = LabelEncoder()\n",
    "    le_away = LabelEncoder()\n",
    "    \n",
    "    # Handle missing tournaments\n",
    "    features_df['tournament'] = features_df['tournament'].fillna('Unknown')\n",
    "    \n",
    "    # Encode teams and tournaments\n",
    "    features_df['tournament_encoded'] = le_tournament.fit_transform(features_df['tournament'].astype(str))\n",
    "    features_df['home_team_encoded'] = le_home.fit_transform(features_df['home-team'].astype(str))\n",
    "    features_df['away_team_encoded'] = le_away.fit_transform(features_df['away-team'].astype(str))\n",
    "    \n",
    "    # Odds-based features (when available)\n",
    "    odds_cols = ['pre-match_odds_home', 'pre-match_odds_draw', 'pre-match_odds_away']\n",
    "    for col in odds_cols:\n",
    "        features_df[col] = pd.to_numeric(features_df[col], errors='coerce')\n",
    "    \n",
    "    # Calculate implied probabilities from odds\n",
    "    features_df['home_prob'] = 1 / features_df['pre-match_odds_home']\n",
    "    features_df['draw_prob'] = 1 / features_df['pre-match_odds_draw'] \n",
    "    features_df['away_prob'] = 1 / features_df['pre-match_odds_away']\n",
    "    \n",
    "    # Normalize probabilities\n",
    "    total_prob = features_df['home_prob'] + features_df['draw_prob'] + features_df['away_prob']\n",
    "    features_df['home_prob_norm'] = features_df['home_prob'] / total_prob\n",
    "    features_df['draw_prob_norm'] = features_df['draw_prob'] / total_prob\n",
    "    features_df['away_prob_norm'] = features_df['away_prob'] / total_prob\n",
    "    \n",
    "    # Half-time score features\n",
    "    features_df['home_ht_goals'] = pd.to_numeric(features_df['home_ht_goals'], errors='coerce')\n",
    "    features_df['away_ht_goals'] = pd.to_numeric(features_df['away_ht_goals'], errors='coerce')\n",
    "    features_df['ht_goal_diff'] = features_df['home_ht_goals'] - features_df['away_ht_goals']\n",
    "    \n",
    "    # Team strength proxies (based on odds when available)\n",
    "    features_df['team_strength_diff'] = features_df['away_prob_norm'] - features_df['home_prob_norm']\n",
    "    \n",
    "    return features_df\n",
    "\n",
    "# Create features for both datasets\n",
    "df_ht0_features = create_features(df_ht0)\n",
    "df_ht1_features = create_features(df_ht1)\n",
    "\n",
    "# Select feature columns\n",
    "feature_cols = [\n",
    "    'tournament_encoded', 'home_team_encoded', 'away_team_encoded',\n",
    "    'home_prob_norm', 'draw_prob_norm', 'away_prob_norm', 'team_strength_diff',\n",
    "    'home_ht_goals', 'away_ht_goals', 'ht_goal_diff'\n",
    "]\n",
    "\n",
    "# Function to prepare data for modeling\n",
    "def prepare_model_data(df_features, target_col='target'):\n",
    "    # Select features that exist and have data\n",
    "    available_features = [col for col in feature_cols if col in df_features.columns]\n",
    "    \n",
    "    X = df_features[available_features].copy()\n",
    "    y = df_features[target_col].copy()\n",
    "    \n",
    "    # Fill missing values\n",
    "    X = X.fillna(X.mean())\n",
    "    \n",
    "    # Remove any remaining NaN rows\n",
    "    mask = ~(X.isna().any(axis=1) | y.isna())\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    \n",
    "    return X, y, available_features\n",
    "\n",
    "# Prepare data for both scenarios\n",
    "X_ht0, y_ht0, features_ht0 = prepare_model_data(df_ht0_features)\n",
    "X_ht1, y_ht1, features_ht1 = prepare_model_data(df_ht1_features)\n",
    "\n",
    "print(f\"\\nHT=0 model: {X_ht0.shape[0]} samples, {X_ht0.shape[1]} features\")\n",
    "print(f\"HT=1 model: {X_ht1.shape[0]} samples, {X_ht1.shape[1]} features\")\n",
    "\n",
    "# Function to create and train model\n",
    "def create_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train model for HT=0 scenario\n",
    "if len(X_ht0) > 100:  # Ensure we have enough data\n",
    "    X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(\n",
    "        X_ht0, y_ht0, test_size=0.2, random_state=42, stratify=y_ht0\n",
    "    )\n",
    "    \n",
    "    scaler_0 = StandardScaler()\n",
    "    X_train_0_scaled = scaler_0.fit_transform(X_train_0)\n",
    "    X_test_0_scaled = scaler_0.transform(X_test_0)\n",
    "    \n",
    "    model_ht0 = create_model(X_train_0_scaled.shape[1])\n",
    "    \n",
    "    history_0 = model_ht0.fit(\n",
    "        X_train_0_scaled, y_train_0,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate HT=0 model\n",
    "    y_pred_0 = (model_ht0.predict(X_test_0_scaled) > 0.5).astype(int)\n",
    "    y_proba_0 = model_ht0.predict(X_test_0_scaled)\n",
    "    \n",
    "    print(\"\\n=== HT=0 Model Results ===\")\n",
    "    print(f\"Accuracy: {(y_pred_0.flatten() == y_test_0).mean():.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_0, y_pred_0))\n",
    "\n",
    "# Train model for HT=1 scenario\n",
    "if len(X_ht1) > 100:  # Ensure we have enough data\n",
    "    X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(\n",
    "        X_ht1, y_ht1, test_size=0.2, random_state=42, stratify=y_ht1\n",
    "    )\n",
    "    \n",
    "    scaler_1 = StandardScaler()\n",
    "    X_train_1_scaled = scaler_1.fit_transform(X_train_1)\n",
    "    X_test_1_scaled = scaler_1.transform(X_test_1)\n",
    "    \n",
    "    model_ht1 = create_model(X_train_1_scaled.shape[1])\n",
    "    \n",
    "    history_1 = model_ht1.fit(\n",
    "        X_train_1_scaled, y_train_1,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate HT=1 model\n",
    "    y_pred_1 = (model_ht1.predict(X_test_1_scaled) > 0.5).astype(int)\n",
    "    y_proba_1 = model_ht1.predict(X_test_1_scaled)\n",
    "    \n",
    "    print(\"\\n=== HT=1 Model Results ===\")\n",
    "    print(f\"Accuracy: {(y_pred_1.flatten() == y_test_1).mean():.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_1, y_pred_1))\n",
    "\n",
    "# High-confidence prediction analysis\n",
    "def analyze_high_confidence_predictions(model, X_test_scaled, y_test, y_proba, threshold=0.9):\n",
    "    \"\"\"Analyze predictions with high confidence (>90% or <10% probability)\"\"\"\n",
    "    \n",
    "    high_conf_mask = (y_proba.flatten() > threshold) | (y_proba.flatten() < (1-threshold))\n",
    "    \n",
    "    if high_conf_mask.sum() > 0:\n",
    "        high_conf_pred = (y_proba[high_conf_mask] > 0.5).astype(int)\n",
    "        high_conf_actual = y_test[high_conf_mask]\n",
    "        high_conf_proba = y_proba[high_conf_mask]\n",
    "        \n",
    "        accuracy = (high_conf_pred.flatten() == high_conf_actual).mean()\n",
    "        \n",
    "        print(f\"\\nHigh Confidence Predictions (>{threshold:.0%} or <{1-threshold:.0%}):\")\n",
    "        print(f\"Number of high-confidence predictions: {high_conf_mask.sum()}\")\n",
    "        print(f\"Percentage of total: {high_conf_mask.mean():.2%}\")\n",
    "        print(f\"Accuracy on high-confidence predictions: {accuracy:.4f}\")\n",
    "        \n",
    "        return high_conf_mask, accuracy\n",
    "    else:\n",
    "        print(f\"\\nNo predictions with >{threshold:.0%} confidence found\")\n",
    "        return None, 0\n",
    "\n",
    "# Analyze high-confidence predictions\n",
    "if len(X_ht0) > 100:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"HIGH-CONFIDENCE ANALYSIS - HT=0 MODEL\")\n",
    "    high_conf_0, acc_0 = analyze_high_confidence_predictions(model_ht0, X_test_0_scaled, y_test_0, y_proba_0)\n",
    "\n",
    "if len(X_ht1) > 100:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"HIGH-CONFIDENCE ANALYSIS - HT=1 MODEL\")\n",
    "    high_conf_1, acc_1 = analyze_high_confidence_predictions(model_ht1, X_test_1_scaled, y_test_1, y_proba_1)\n",
    "\n",
    "# Feature importance analysis (using permutation importance approximation)\n",
    "def analyze_feature_importance(model, X_test_scaled, y_test, feature_names):\n",
    "    \"\"\"Simple feature importance analysis\"\"\"\n",
    "    base_score = model.evaluate(X_test_scaled, y_test, verbose=0)[1]\n",
    "    importance_scores = []\n",
    "    \n",
    "    for i, feature in enumerate(feature_names):\n",
    "        X_permuted = X_test_scaled.copy()\n",
    "        np.random.shuffle(X_permuted[:, i])\n",
    "        permuted_score = model.evaluate(X_permuted, y_test, verbose=0)[1]\n",
    "        importance = base_score - permuted_score\n",
    "        importance_scores.append(importance)\n",
    "    \n",
    "    # Sort by importance\n",
    "    feature_importance = list(zip(feature_names, importance_scores))\n",
    "    feature_importance.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    \n",
    "    print(\"\\nFeature Importance (by accuracy drop when shuffled):\")\n",
    "    for feature, importance in feature_importance[:10]:\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "if len(X_ht0) > 100:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FEATURE IMPORTANCE - HT=0 MODEL\")\n",
    "    analyze_feature_importance(model_ht0, X_test_0_scaled, y_test_0, features_ht0)\n",
    "\n",
    "if len(X_ht1) > 100:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FEATURE IMPORTANCE - HT=1 MODEL\")\n",
    "    analyze_feature_importance(model_ht1, X_test_1_scaled, y_test_1, features_ht1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "ANALYSIS SUMMARY:\n",
    "1. The model attempts to predict goal probabilities based on available features\n",
    "2. High-confidence predictions (>90% certainty) are analyzed separately\n",
    "3. Feature importance shows which variables matter most\n",
    "\n",
    "ACHIEVING 99% ACCURACY - REALISTIC ASSESSMENT:\n",
    "- 99% accuracy on ALL predictions is extremely difficult with this data\n",
    "- However, 99% accuracy on a SUBSET of high-confidence predictions is more feasible\n",
    "- The key is identifying which games to predict vs. which to skip\n",
    "\n",
    "STRATEGY FOR HIGH-CONFIDENCE PREDICTIONS:\n",
    "1. Focus on matches where the model is >95% confident\n",
    "2. This might be 10-20% of total matches, but with very high accuracy\n",
    "3. Use ensemble methods and additional features for better confidence estimation\n",
    "\n",
    "ADDITIONAL FEATURES THAT COULD IMPROVE ACCURACY:\n",
    "(All easily accessible)\n",
    "\n",
    "1. TEAM FORM FEATURES:\n",
    "   - Last 5 games: goals scored/conceded per team\n",
    "   - Recent head-to-head record\n",
    "   - Home/away form separately\n",
    "\n",
    "2. LEAGUE-SPECIFIC FEATURES:\n",
    "   - Average goals per game in the league\n",
    "   - League defensive/offensive strength ratings\n",
    "   - Season stage (early/mid/late season affects motivation)\n",
    "\n",
    "3. TEMPORAL FEATURES:\n",
    "   - Day of week (weekend vs. weekday affects performance)\n",
    "   - Month/season (weather effects, player fitness)\n",
    "   - Days since last match (rest effects)\n",
    "\n",
    "4. BETTING MARKET FEATURES:\n",
    "   - Over/Under 2.5 goals odds\n",
    "   - Both teams to score odds\n",
    "   - Asian handicap lines\n",
    "\n",
    "5. TEAM STATISTICS:\n",
    "   - League position/points\n",
    "   - Goals for/against ratios\n",
    "   - Average possession percentage\n",
    "\n",
    "6. MATCH CONTEXT:\n",
    "   - Derby matches (local rivals)\n",
    "   - Cup vs. league matches\n",
    "   - Importance of match (relegation/promotion battles)\n",
    "\n",
    "IMPLEMENTATION STRATEGY:\n",
    "1. Start with current model to identify high-confidence predictions\n",
    "2. Add team form features (most impactful)\n",
    "3. Include league context and betting odds\n",
    "4. Use ensemble of multiple models\n",
    "5. Implement strict confidence thresholds (predict only top 10-20% most certain)\n",
    "\n",
    "This approach could realistically achieve 90-99% accuracy on the subset of matches \n",
    "where the model is most confident, while avoiding predictions on uncertain matches.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
